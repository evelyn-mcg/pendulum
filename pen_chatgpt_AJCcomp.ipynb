{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtGx5C0Rq7p2"
      },
      "outputs": [],
      "source": [
        "# openAI setup - base on batching example\n",
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca5Y9VqprP1m",
        "outputId": "f9f5ca45-9adc-4194-8b54-06c7f5767bba"
      },
      "outputs": [
      ],
      "source": [
        "# data setup\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "dataset = pd.read_csv('/content/labelled narrative - not yet labelled.csv')\n",
        "#channels = list(dataset['channel_name'].unique())\n",
        "batch_size = 10\n",
        "max_tokens = 8912 #adjusted for prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh_FJFioHFFS",
        "outputId": "8290f952-a41d-4ed3-8669-25ad8ef05c85"
      },
      "outputs": [
      ],
      "source": [
        "!pip install openai==0.28\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSwls3OP1zZc"
      },
      "outputs": [],
      "source": [
        "def count_tokens(text):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    return len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN2b5JNr3THI"
      },
      "outputs": [],
      "source": [
        "#sort channels by ascending # of snippets for easier batching\n",
        "def snip_sort(df):\n",
        "\n",
        "    snippet_counts = df['channel_name'].value_counts()\n",
        "    sorted_channels = snippet_counts.sort_values().index\n",
        "    channel_order = pd.Categorical(df['channel_name'], categories=sorted_channels, ordered=True)\n",
        "    df_sorted = df.assign(channel_order=channel_order).sort_values('channel_order').drop(columns='channel_order')\n",
        "\n",
        "    return df_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97oZLMO2rFWb"
      },
      "outputs": [],
      "source": [
        "# prompt - input is batch containg n channels and related snippet\n",
        "prompt_str = lambda input: f\"\"\"\n",
        "    Determine whether a channel should be labeled with the AntiSemitic tag. The definition of AntiSemitic tag is: \"Features content created by or for an Antisemitic audience.\n",
        "    Antisemitism is defined as a certain negative perception of Jews, that may be expressed as hatred towards Jewish individuals, community institutions, or the Jewish religion as a whole.\n",
        "    Antisemitism frequently charges Jews with conspiring to harm humanity, and it is often used to blame Jews for “why things go wrong.” Antisemitic creators often employ sinister stereotypes\n",
        "    and negative character traits, especially about money or power, or physical characteristics like large noses. Holocaust denial or pro-Nazi speech is also antisemitic, as well as the dual\n",
        "    loyalty trope, which accuses Jewish citizens of being more loyal to Israel, or to the alleged priorities of Jews worldwide, than to the interests of their own nations.”\n",
        "\n",
        "    You are with a list of one or more channels, and a sample of their posts, labeled \"Channel Name\" and \"Posts\".\n",
        "    Give your answer in one word for each channel, either yes or no.\n",
        "    {input}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8RrgAjjvi1Z"
      },
      "outputs": [],
      "source": [
        "#create formatted input strings and their token count\n",
        "def batch_string(df) -> pd.DataFrame:\n",
        "    aggregated = df.groupby(['channel_name', 'channel_id'])['snippet'].apply(lambda x: '\\n'.join(x)).reset_index()\n",
        "\n",
        "    aggregated['batch_str'] = aggregated.apply(lambda row: f\"Channel Name: {row['channel_name']}\\nPosts: {row['snippet']}\", axis=1)\n",
        "    aggregated['tokens'] = aggregated['batch_str'].apply(count_tokens)\n",
        "\n",
        "    return aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWuon4dQCSnU"
      },
      "outputs": [],
      "source": [
        "# batch strings while maintaining channels, max_tokens\n",
        "def batching(df):\n",
        "  input = []\n",
        "  chans = []\n",
        "  current = []\n",
        "  current_len = 0\n",
        "  batchcount = 0\n",
        "  current_channels = set()\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "      text = row['batch_str']\n",
        "      text_len = row['tokens']\n",
        "      channel = row['channel_name']\n",
        "\n",
        "      if current_len + text_len > max_tokens:\n",
        "          if current:\n",
        "              input.append(' '.join(current))\n",
        "              chans.append(len(current_channels))\n",
        "          current = [text]\n",
        "          current_channels = {channel}\n",
        "          current_len = text_len\n",
        "      else:\n",
        "          current.append(text)\n",
        "          current_len += text_len\n",
        "          current_channels.add(channel)\n",
        "\n",
        "    # Append the last chunk if it's not empty\n",
        "  if current:\n",
        "      input.append(' '.join(current))\n",
        "      chans.append(len(current_channels))\n",
        "\n",
        "  return input, chans #list of input strings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqnOwbH9ArxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "450d7fcc-73c4-4ce5-dd9c-a8b2188e0bb8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "sorted_df = snip_sort(dataset)\n",
        "\n",
        "#create new column input which is the formatted string\n",
        "#and column to count tokens\n",
        "sorted_df['snippet'] = sorted_df['snippet'].astype(str).fillna('')\n",
        "sorted_df = batch_string(sorted_df)\n",
        "\n",
        "input, chan_tracker = batching(sorted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "38_aYtZNY6LV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "e3638389-c941-4f3a-ff1c-35e3e627e350"
      },
      "outputs": [
      ],
      "source": [
        "\n",
        "prompts = [prompt_str(ins) for ins in input]\n",
        "input_df = pd.DataFrame({\n",
        "    'prompt': prompts,\n",
        "    'channels': chan_tracker\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpxvpRZ1TgNq",
        "outputId": "ce39f3c5-3eb5-495f-9ddc-ea7917bef422"
      },
      "outputs": [
      ],
      "source": [
        "# classification task\n",
        "input_df[\"output\"] = input_df['prompt'].progress_apply(lambda prompt: get_response(prompt))\n",
        "\n",
        "input_df[\"prompt_tokens\"] = input_df[\"output\"].apply(lambda x: x[0])\n",
        "input_df[\"completion_tokens\"] = input_df[\"output\"].apply(lambda x: x[1])\n",
        "input_df[\"output\"] = input_df[\"output\"].apply(lambda x: x[2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_df['output'].to_csv('output.csv', index=False)\n",
        "input_df.to_csv('input.csv', index=False)"
      ],
      "metadata": {
        "id": "tWm4hVGtjVai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = input_df['output']\n",
        "channel_names = []\n",
        "labels = []\n",
        "for cell in ds:\n",
        "    # Split the cell into lines\n",
        "    lines = cell.split('\\n')\n",
        "    for line in lines:\n",
        "        # Split the line on ' - '\n",
        "        parts = line.split(' - ')\n",
        "        if len(parts) == 2:\n",
        "            # Extract channel name and label\n",
        "            channel_name = parts[0].replace('Channel Name: ', '').strip()\n",
        "            label = parts[1].strip()\n",
        "            # Append to lists\n",
        "            channel_names.append(channel_name)\n",
        "            labels.append(label)\n"
      ],
      "metadata": {
        "id": "pm6K9oAChI2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame({\n",
        "    'channel_name': channel_names,\n",
        "    'label': labels\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hIDqbJTMiCWI",
        "outputId": "173f162b-c9a9-4e6e-cd95-8ca507302c54"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv(\"labels.csv\", index = False)"
      ],
      "metadata": {
        "id": "OF-VvqmajENX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o41XfbHOFe3d"
      },
      "outputs": [],
      "source": [
        "# classification task\n",
        "def get_response(prompt, model=\"gpt-4\", temperature=0.0, verbose=True):\n",
        "    openai.api_key = api_key\n",
        "    openai.api_base = \"https://api.openai.com/v1/\"\n",
        "\n",
        "    for _ in range(5):\n",
        "        try:\n",
        "            chat_completion = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                temperature=temperature,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "            )\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Error. Trying again.\")\n",
        "    else:\n",
        "        return \"Error\"\n",
        "\n",
        "    response = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
        "    if not verbose:\n",
        "        return response\n",
        "\n",
        "    prompt_tokens = chat_completion[\"usage\"][\"prompt_tokens\"]\n",
        "    completion_tokens = chat_completion[\"usage\"][\"completion_tokens\"]\n",
        "\n",
        "    return prompt_tokens, completion_tokens, response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpEKhFzl7CZA"
      },
      "outputs": [],
      "source": [
        "output = pd.read_csv('output_df', sep = 'Answer', engine='python')\n",
        "output.to_csv('out.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
